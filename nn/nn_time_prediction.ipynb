{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13509\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\13509\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = pd.read_csv('static-pre-process.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "static_1 = static.copy()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "static_1['race_encoded'] = scaler.fit_transform(static_1[['race_encoded']])\n",
    "static_1['icu_outtime'] = pd.to_datetime(static_1['icu_outtime'])\n",
    "static_1['icu_intime'] = pd.to_datetime(static_1['icu_intime'])\n",
    "\n",
    "\n",
    "# Calculate ICU stay duration in hours and keep only the total number of hours\n",
    "#static_1['icu_hours'] = (static_1['icu_outtime'] - static_1['icu_intime']).dt.total_seconds() / 3600\n",
    "\n",
    "static_1.drop(['admission_type','first_careunit'], axis=1, inplace=True)\n",
    "\n",
    "static_1.sort_values(by='id', ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20414, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_2 = static_1.loc[:,'admission_age':'gender_encoded']\n",
    "numpy_array = static_2.to_numpy()\n",
    "static_data = torch.tensor(numpy_array, dtype=torch.float32)\n",
    "static_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('dynamic-pre-process.csv')\n",
    "ts1 = ts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ts1.groupby('id')\n",
    "tensor_list = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    values = group.loc[:,'albumin':].values\n",
    "    tensor_list.append(torch.tensor(values, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_ts = [t.shape[0] for t in tensor_list]\n",
    "average_length = sum(lst_ts) / len(lst_ts)\n",
    "math.ceil(average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_length = 5\n",
    "num_features = len(ts1.columns) - list(ts1.columns).index('albumin')\n",
    "final_tensors = []\n",
    "for t in tensor_list:\n",
    "    if t.shape[0] > ave_length:\n",
    "        t = t[:ave_length, :]\n",
    "    elif t.shape[0] < ave_length:\n",
    "        padding_needed = ave_length - t.shape[0]\n",
    "        padding = torch.zeros(padding_needed, num_features, dtype=t.dtype)\n",
    "        t = torch.cat([t, padding], dim=0)\n",
    "    final_tensors.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20414, 5, 68])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data = torch.stack(final_tensors)\n",
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20414, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1 = static_1['los_icu']\n",
    "labels = torch.tensor(label_1.values.reshape(-1, 1), dtype=torch.float32)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49326</th>\n",
       "      <td>20001305</td>\n",
       "      <td>unilat lower ext veins right  year old woman w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49325</th>\n",
       "      <td>20001305</td>\n",
       "      <td>with copd in resp distress intubated evaluate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37633</th>\n",
       "      <td>20001361</td>\n",
       "      <td>renal ultrasound portable  man with acute rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37629</th>\n",
       "      <td>20001361</td>\n",
       "      <td>chest xray dated  none  male with seizure and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37630</th>\n",
       "      <td>20001361</td>\n",
       "      <td>ct of the head dated   yo male with overdose a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>29999625</td>\n",
       "      <td>ct head wo contrast  with pfossa bleed seen on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>29999625</td>\n",
       "      <td>chest xray  pmh of htn presented with medial r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>29999625</td>\n",
       "      <td>chest portable ap  pmh of htn presented with m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>29999625</td>\n",
       "      <td>ct head wo contrast  pmh of htn presented with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>29999625</td>\n",
       "      <td>intubated tube placement single portable view...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81206 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "49326  20001305  unilat lower ext veins right  year old woman w...\n",
       "49325  20001305   with copd in resp distress intubated evaluate...\n",
       "37633  20001361  renal ultrasound portable  man with acute rena...\n",
       "37629  20001361  chest xray dated  none  male with seizure and ...\n",
       "37630  20001361  ct of the head dated   yo male with overdose a...\n",
       "...         ...                                                ...\n",
       "2741   29999625  ct head wo contrast  with pfossa bleed seen on...\n",
       "2744   29999625  chest xray  pmh of htn presented with medial r...\n",
       "2743   29999625  chest portable ap  pmh of htn presented with m...\n",
       "2742   29999625  ct head wo contrast  pmh of htn presented with...\n",
       "2740   29999625   intubated tube placement single portable view...\n",
       "\n",
       "[81206 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_csv('cleaned_notes.csv')\n",
    "text = text[['id','text']]\n",
    "text['text'] = text['text'].str.replace('\\n', ' ', regex=False)\n",
    "text.sort_values(by='id', ascending=True, inplace=True)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001305</td>\n",
       "      <td>unilat lower ext veins right  year old woman w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001361</td>\n",
       "      <td>renal ultrasound portable  man with acute rena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001770</td>\n",
       "      <td>dx chest portable picc line placement  year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20002506</td>\n",
       "      <td>us renal artery doppler  year old man with iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20003425</td>\n",
       "      <td>ct chest wo contrast  year old man with htn hl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20409</th>\n",
       "      <td>29997500</td>\n",
       "      <td>year old woman with poorly differentiated epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20410</th>\n",
       "      <td>29997616</td>\n",
       "      <td>history  with asthma exacerbation preceding pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20411</th>\n",
       "      <td>29998399</td>\n",
       "      <td>pelvis ap inlet and outlet left acetabular fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20412</th>\n",
       "      <td>29999498</td>\n",
       "      <td>male with metastatic melanoma now with hyperc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20413</th>\n",
       "      <td>29999625</td>\n",
       "      <td>ct head wo contrast  with pfossa bleed seen on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20414 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0      20001305  unilat lower ext veins right  year old woman w...\n",
       "1      20001361  renal ultrasound portable  man with acute rena...\n",
       "2      20001770  dx chest portable picc line placement  year ol...\n",
       "3      20002506  us renal artery doppler  year old man with iph...\n",
       "4      20003425  ct chest wo contrast  year old man with htn hl...\n",
       "...         ...                                                ...\n",
       "20409  29997500   year old woman with poorly differentiated epi...\n",
       "20410  29997616  history  with asthma exacerbation preceding pr...\n",
       "20411  29998399  pelvis ap inlet and outlet left acetabular fra...\n",
       "20412  29999498   male with metastatic melanoma now with hyperc...\n",
       "20413  29999625  ct head wo contrast  with pfossa bleed seen on...\n",
       "\n",
       "[20414 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_merged = text.groupby('id')['text'].agg(' '.join).reset_index()\n",
    "text_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_merged['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, static_data, ts_data, texts, labels):\n",
    "        self.static_data = static_data\n",
    "        self.ts_data = ts_data\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_tokens = self.tokenizer(self.texts[idx], return_tensors='pt', padding=True, truncation=True, max_length=128, add_special_tokens=True)\n",
    "        return (\n",
    "            self.static_data[idx],\n",
    "            self.ts_data[idx],\n",
    "            text_tokens['input_ids'].squeeze(0),\n",
    "            text_tokens['attention_mask'].squeeze(0),\n",
    "            self.labels[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    static_data, ts_data, input_ids, attention_masks, labels = zip(*batch)\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    static_data = torch.stack(static_data)\n",
    "    ts_data = torch.stack(ts_data)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return static_data, ts_data, input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "(train_static, test_static, \n",
    " train_ts, test_ts, \n",
    " train_texts, test_texts, \n",
    " train_labels, test_labels) = train_test_split(static_data, ts_data, text_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_static, train_ts, train_texts, train_labels)\n",
    "test_dataset = CustomDataset(test_static, test_ts, test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        self.static_layer = nn.Sequential(\n",
    "            nn.Linear(16, 16), # 16 features\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=68, hidden_size=16, batch_first=True) #68 features\n",
    "        self.bert = bert_model\n",
    "        # self.bert_to_hidden = nn.Linear(768, 256)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 + 16 + 768, 16),  # LSTM and static 32 dimï¼ŒBERT output 768 dim\n",
    "            # nn.Linear(32 + 64 + 256, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, static_data, ts_data, input_ids, attention_mask):\n",
    "        static_features = self.static_layer(static_data)\n",
    "        _, (hidden, _) = self.lstm(ts_data)\n",
    "        lstm_features = hidden[-1]\n",
    "        text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        # text_features = self.bert_to_hidden(text_features)\n",
    "        combined_features = torch.cat([static_features, lstm_features, text_features], dim=1)\n",
    "        output = self.fc(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.002147998893633485 (16, 0.0001)\n",
      "Epoch 2, Loss: 0.0015150908147916198 (16, 0.0001)\n",
      "Epoch 3, Loss: 0.0005369987338781357 (16, 0.0001)\n",
      "Epoch 4, Loss: 0.0033159013837575912 (16, 0.0001)\n",
      "Epoch 5, Loss: 0.0020625744946300983 (16, 0.0001)\n",
      "Test MSE: 0.004019141474485757 (16, 0.0001)\n",
      "Epoch 1, Loss: 0.00019445612269919366 (32, 0.0001)\n",
      "Epoch 2, Loss: 0.0010307560442015529 (32, 0.0001)\n",
      "Epoch 3, Loss: 0.0049176146276295185 (32, 0.0001)\n",
      "Epoch 4, Loss: 0.013914750888943672 (32, 0.0001)\n",
      "Epoch 5, Loss: 0.0030324032995849848 (32, 0.0001)\n",
      "Test MSE: 0.004314338567876787 (32, 0.0001)\n"
     ]
    }
   ],
   "source": [
    "for i in [(16,0.0001),(32,0.0001)]:  \n",
    "    class MultiInputModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MultiInputModel, self).__init__()\n",
    "            self.static_layer = nn.Sequential(\n",
    "                nn.Linear(16, i[0]), # 16 features\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.lstm = nn.LSTM(input_size=68, hidden_size=i[0], batch_first=True) #68 features\n",
    "            self.bert = bert_model\n",
    "            # self.bert_to_hidden = nn.Linear(768, 256)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(i[0] + i[0] + 768, i[0]),  # LSTM and static 32 dimï¼ŒBERT output 768 dim\n",
    "                # nn.Linear(32 + 64 + 256, 64)\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(i[0], 1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, static_data, ts_data, input_ids, attention_mask):\n",
    "            static_features = self.static_layer(static_data)\n",
    "            _, (hidden, _) = self.lstm(ts_data)\n",
    "            lstm_features = hidden[-1]\n",
    "            text_features = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "            # text_features = self.bert_to_hidden(text_features)\n",
    "            combined_features = torch.cat([static_features, lstm_features, text_features], dim=1)\n",
    "            output = self.fc(combined_features)\n",
    "            return output\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model = MultiInputModel()\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=i[1])\n",
    "    num_epochs = 5\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            static_data, ts_data, input_ids, attention_mask, labels = data\n",
    "\n",
    "            static_data = static_data.to(device)\n",
    "            ts_data = ts_data.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(static_data, ts_data, input_ids, attention_mask)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = loss_function(output, labels.float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}',i)\n",
    "    model.eval()\n",
    "\n",
    "    total_mse = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            static_data, ts_data, input_ids, attention_mask, labels = data\n",
    "\n",
    "            static_data = static_data.to(device)\n",
    "            ts_data = ts_data.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(static_data, ts_data, input_ids, attention_mask)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = loss_function(output, labels.float())\n",
    "\n",
    "            total_mse += loss.item() * labels.size(0)\n",
    "            num_samples += labels.size(0)\n",
    "\n",
    "    average_mse = total_mse / num_samples\n",
    "    print(f'Test MSE: {average_mse}',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.003921828034032568\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "total_mse = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        static_data, ts_data, input_ids, attention_mask, labels = data\n",
    "\n",
    "        static_data = static_data.to(device)\n",
    "        ts_data = ts_data.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(static_data, ts_data, input_ids, attention_mask)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = loss_function(output, labels.float())\n",
    "\n",
    "        total_mse += loss.item() * labels.size(0)\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "average_mse = total_mse / num_samples\n",
    "print(f'Test MSE: {average_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
